[DEFAULT]

# ***Environment
EnvPath0 = ./wads/my_way_home_shortmap_vsp.cfg
EnvPath1 = ./wads/my_way_home_shortmap_vsp.cfg

DeepMonitorization = 0

# pre-process setup
FrameStack = 4
FrameSkip = 4
UseStackedFrames = 1
StackMode = 0
Resolution_H = 42
Resolution_W = 42

Role_as_input = 1
Action_as_input = 1

# ***Env SETTING

#dense,sparse,verysparse
Room_setting = sparse

#0,1
Use_centralized_critic = 1

# ***rollout config
NumEpisodes = 6000
MaxStepsRollout = 50
MaxStepsEpisode = 2600

# *** NUM AGENTS AND PARALLEL ENVS
NumWorkers = 2

# parallel envs
NumParallelEnvs = 3

#GPU related
UseGPU = 1
GPUDeviceID = 2

# agent/actor
BalanceExplorationAdaptative = 0
KnowledgeDistillation = 0
IntCoef = 1
ExtCoef = 3[DEFAULT]

# ***Environment
EnvPath0 = ./wads/my_way_home_shortmap_modificationsssws.cfg
EnvPath1 = ./wads/my_way_home_shortmap_modificationsssws.cfg

#EnvPath0 = ./wads/my_way_home_setup1.cfg
#EnvPath1 = ./wads/my_way_home_setup1.cfg

DeepMonitorization = 0

# pre-process setup
FrameStack = 4
FrameSkip = 4
UseStackedFrames = 1
StackMode = 0
Resolution_H = 42
Resolution_W = 42

Role_as_input = 1
Action_as_input = 1

# ***Env SETTING

#dense,sparse,verysparse
Room_setting = sparse

#0,1
Use_centralized_critic = 1

# ***rollout config
NumEpisodes = 6000
MaxStepsRollout = 50
MaxStepsEpisode = 2600

# *** NUM AGENTS AND PARALLEL ENVS
NumWorkers = 2

# parallel envs
NumParallelEnvs = 3

#GPU related
UseGPU = 1
GPUDeviceID = 1

# agent/actor
BalanceExplorationAdaptative = 0
IntCoef = 1
ExtCoef = 3
ACLearningRate = 1e-4
Epoch = 4
Entropy = 0.01
PPOEps = 0.2
Lambda = 0.95
INTGamma = 0.99
Gamma = 0.99
UseGAE = 1
ClipGradNorm = 1.0


# Type of curosity --> counts: count_c,count_i
# Type of curosity --> rnd: centralized,individual
# Type of curiosity -- none: only Extrinsic signals
Curiosity_type = count_i

# if want to check results of (https://arxiv.org/pdf/1905.12127.pdf)
# independent,minimum,covering,burrowing (just when being individual)
Curiosity_subtype = independent

# make the curiosity also based on action
ActionBasedCuriosity = 0

# Prunning based on reproducibility
Tree_filtering = 0

# Number of Episodes for Observation normalization schema
ObsNormEp = 0

# Use a pre-defined std value to normalize intrinsic rewards
NormalizationStdConstant = 0
NormalizationStd = 1000

# Intrins rewards are treated episodic (the discounted return is initialized after episode finished)
EpisodicIntrinsicRew = 1

# Other RND params if it is being used
RNDLearningRate = 1e-4
UpdateProportion = 1.0
# Used to see the impact on training one of the agents with its samples and also the other agents collected experiences
# Only possible to apply when using individual curiosity type
DecayBaseWorkerCuriosity = 0

#LSTM
use_lstm = 1
hidden_size = 128
bidirectional = 0

# Evaluation/testing (when using 1 unique worker)
trainActor = 1
loadActor = 0
trainCritic = 1
loadCritic = 0
pathActor0 = /home/alain/Desktop/indiv_nolstm_1/models/agent0_actor_5600.pth
pathCritic0 = /home/alain/Desktop/indiv_nolstm_1/models/agent0_critc_5600.pth
pathActor1 = /home/alain/Desktop/indiv_nolstm_1/models/agent1_actor_5600.pth
pathCritic1 = /home/alain/Desktop/indiv_nolstm_1/models/agent1_critc_5600.pth

#Others
NumMiniBatches = 1
DumpEvery = 10
DumpModelsEvery = 50

KLCoef = 0.01
ACLearningRate = 1e-4
Epoch = 4
Entropy = 0.01
PPOEps = 0.2
Lambda = 0.95
INTGamma = 0.99
Gamma = 0.99
UseGAE = 1
ClipGradNorm = 1.0


# *** RND
#centralized,individual,count_c,count_i,none
Curiosity_type = count_i
# independent,minimum,covering,burrowing
Curiosity_subtype = independent
ActionBasedCuriosity = 0
ObsNormEp = 0
NormalizationStdConstant = 0
NormalizationStd = 1000
EpisodicIntrinsicRew = 1
RNDLearningRate = 1e-4
UpdateProportion = 1.0
DecayBaseWorkerCuriosity = 0

#LSTM
use_lstm = 1
hidden_size = 128
bidirectional = 0

#Attention
use_attention = 0
self_attention = 0
#att_mem_observations = 0
attn_heads = 1
window_size = 20

# Evaluation/testing (when using 1 unique worker)
trainActor = 1
loadActor = 0
trainCritic = 1
loadCritic = 0
pathActor0 = /home/alain/Desktop/indiv_nolstm_1/models/agent0_actor_5600.pth
pathCritic0 = /home/alain/Desktop/indiv_nolstm_1/models/agent0_critc_5600.pth
pathActor1 = /home/alain/Desktop/indiv_nolstm_1/models/agent1_actor_5600.pth
pathCritic1 = /home/alain/Desktop/indiv_nolstm_1/models/agent1_critc_5600.pth

#Others
BatchSize = 64
NumMiniBatches = 1
DumpEvery = 10
DumpModelsEvery = 50
